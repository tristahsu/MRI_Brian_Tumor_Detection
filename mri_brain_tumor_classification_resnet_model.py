# -*- coding: utf-8 -*-
"""MRI Brain Tumor Classification Resnet model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t42MWN5OlGkDvscwgY7v57FMuyk4zkfx

# **1. Install packages**
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install torchmetrics
# !pip install torchinfo
# !pip install seaborn

"""# **2. Import libraries**"""

# Data handling
import numpy as np
import pandas as pd

# Data visualization
import seaborn as sns
import matplotlib.pyplot as plt
from PIL import Image

# Preprocessing
from sklearn.model_selection import train_test_split as tts
from torchvision import transforms
import cv2

# Torch
import torch
from torch import nn, optim
from torchinfo import summary
from torch.utils.data import Dataset, DataLoader
from torchvision.models import resnet50 # model resnet

# Metrics
from sklearn.metrics import confusion_matrix, classification_report
from torchmetrics.classification import MulticlassAccuracy

# os
import os

# Path
from pathlib import Path

# tqdm
from tqdm.auto import tqdm

# random
import random

# typing
from typing import Dict,List

# Warnings
import warnings
warnings.filterwarnings("ignore")

"""# **3. Load data and EDA**"""

from google.colab import drive
drive.mount('/gdrive')

# Classes we have in our data set.
total_classes = os.listdir(r'/gdrive/MyDrive/New_MRI_images')
total_classes

# Total number of images per class.
images_path = Path(r'/gdrive/MyDrive/New_MRI_images')

for c in total_classes:
  print(f'* {c}', '=',len(os.listdir(os.path.join(images_path, c))), 'images')

# Let's display 1 image per class.

fig,ax = plt.subplots(1,4,figsize=(10,4))
ax = ax.flat
for i,c in enumerate(total_classes):
  img_total_class = list(Path(os.path.join(images_path, c)).glob("*.png"))
  img_selected = random.choice(img_total_class)
  img_BGR = cv2.imread(str(img_selected))
  img_RGB = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2RGB)
  height,width,channel = img_RGB.shape
  ax[i].imshow(img_RGB)
  ax[i].set_title(f"{img_selected.parent.stem}\nheight:{height}\nwidth:{width}")
  ax[i].axis("off")

fig.tight_layout()
fig.show()

# Routes where the images are located.
images_path_list = list(images_path.glob("*/*.png"))
total_images = len(images_path_list)

# We store the heights of the images.
seq_height = [None]*total_images
# We store the width of the images.
seq_width = [None]*total_images

for i,img_path in enumerate(images_path_list):
  img = Image.open(img_path)
  seq_height[i] = img.height
  seq_width[i] = img.width

# Let's visualize the distribution of the length and width of the images.

fig,ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10,4))
plt.style.use("ggplot")
ax = ax.flat

sns.histplot(seq_height,
             kde = True,
             color = "darkred",
             ax = ax[0])
ax[0].spines["top"].set_visible(False)
ax[0].spines["right"].set_visible(False)
ax[0].set_title("Distribution of Height", fontweight = "bold", color = "black")

sns.histplot(seq_width,
             kde = True,
             color = "darkblue",
             ax = ax[1])
ax[1].spines["top"].set_visible(False)
ax[1].spines["right"].set_visible(False)
ax[1].set_title("Distribution of Width", fontweight = "bold", color = "black")

fig.tight_layout()
fig.show()

"""# **4. Preprocessing**"""

# We create a pd.DataFrame where we will store the paths of the images and their class
# and then iterate and create our set of images and labels.
img_path_and_class = {"img_path":[],
                      "classes":[]}

for i in images_path_list:
  img_path_and_class["img_path"].append(i)
  img_path_and_class["classes"].append(i.parent.stem)

df_img_path_and_class = pd.DataFrame(img_path_and_class)
df_img_path_and_class.head()

# We define the transformations that are applied to the training and testing data.
train_transforms = transforms.Compose([
    transforms.Resize((128,128)),
    transforms.RandomHorizontalFlip(p = 0.5),
    transforms.ToTensor()])

test_transforms = transforms.Compose([
    transforms.Resize((128,128)),
    transforms.ToTensor()])

# Now let's separate our pd.DataFrame into path's and classes.
X = df_img_path_and_class.drop("classes", axis = 1)
y = df_img_path_and_class["classes"]

# Classes we have in our data set.
original_total_classes = os.listdir(r'/gdrive/MyDrive/Test_dataset/data')
original_total_classes

# Total number of images per class.
original_images_path = Path(r'/gdrive/MyDrive/Test_dataset/data')

for c in original_total_classes:
  print(f'* {c}', '=',len(os.listdir(os.path.join(original_images_path, c))), 'images')

# Let's display 1 image per class.

fig,ax = plt.subplots(1,4,figsize=(10,4))
ax = ax.flat
for i,c in enumerate(original_total_classes):
  img_total_class = list(Path(os.path.join(original_images_path, c)).glob("*.jpg"))
  img_selected = random.choice(img_total_class)
  img_BGR = cv2.imread(str(img_selected))
  img_RGB = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2RGB)
  height,width,channel = img_RGB.shape
  ax[i].imshow(img_RGB)
  ax[i].set_title(f"{img_selected.parent.stem}\nheight:{height}\nwidth:{width}")
  ax[i].axis("off")

fig.tight_layout()
fig.show()

# Routes where the images are located.
original_images_path_list = list(original_images_path.glob("*/*.jpg"))
original_total_images = len(original_images_path_list)

# We store the heights of the images.
original_seq_height = [None]*original_total_images
# We store the width of the images.
original_seq_width = [None]*original_total_images

for i,img_path in enumerate(original_images_path_list):
  img = Image.open(img_path)
  original_seq_height[i] = img.height
  original_seq_width[i] = img.width

# Let's visualize the distribution of the length and width of the images.

fig,ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10,4))
plt.style.use("ggplot")
ax = ax.flat

sns.histplot(original_seq_height,
             kde = True,
             color = "darkred",
             ax = ax[0])
ax[0].spines["top"].set_visible(False)
ax[0].spines["right"].set_visible(False)
ax[0].set_title("Distribution of Height", fontweight = "bold", color = "black")

sns.histplot(original_seq_width,
             kde = True,
             color = "darkblue",
             ax = ax[1])
ax[1].spines["top"].set_visible(False)
ax[1].spines["right"].set_visible(False)
ax[1].set_title("Distribution of Width", fontweight = "bold", color = "black")

fig.tight_layout()
fig.show()

# We create a pd.DataFrame where we will store the paths of the images and their class
# and then iterate and create our set of images and labels.
original_img_path_and_class = {"img_path":[],
                      "classes":[]}

for i in original_images_path_list:
  original_img_path_and_class["img_path"].append(i)
  original_img_path_and_class["classes"].append(i.parent.stem)

df_original_img_path_and_class = pd.DataFrame(original_img_path_and_class)
df_original_img_path_and_class.head()

# We divide into training and testing.
# We define the random seed for reproducibility.
SEED = 42
X_train = X
y_train = y
X_test = df_original_img_path_and_class.drop("classes", axis = 1)
y_test = df_original_img_path_and_class["classes"]

# We visualize how many images we have per class in both the training and test set.
# Visualization of the objective variable in the training and test set.
df_pct_train = y_train.value_counts().to_frame()
df_pct_train = df_pct_train.rename(columns = {'y':'count'})

labels_train = df_pct_train.index.to_list()
values_train = df_pct_train.iloc[:,0]

df_pct_test = y_test.value_counts().to_frame()
df_pct_test = df_pct_test.rename(columns = {'y':'count'})

labels_test = df_pct_test.index.to_list()
values_test = df_pct_test.iloc[:,0]


fig,axes = plt.subplots(1,2,figsize = (9,4))

def autopct_fun(abs_values):
    gen = iter(abs_values)
    return lambda pct: f"{pct:.1f}%\n({next(gen)})"


axes[0].pie(x = values_train, labels = labels_train, autopct = autopct_fun(values_train),
            wedgeprops = {'linewidth':1.2, 'edgecolor':'black'},
            textprops = {'fontsize':10, 'fontweight':'bold'},
            colors = ["r","b","g","skyblue"])
axes[0].set_title('Train', fontsize = 14, fontweight = 'bold', color = 'darkblue')
axes[0].axis("equal")

axes[1].pie(x = values_test, labels = labels_test, autopct = autopct_fun(values_test),
            wedgeprops = {'linewidth':1.2, 'edgecolor':'black'},
            textprops = {'fontsize':10, 'fontweight':'bold'},
            colors = ["r","b","g","skyblue"])
axes[1].set_title('Test', fontsize = 14, fontweight = 'bold', color = 'darkblue')
axes[1].axis("equal")

fig.tight_layout()
fig.subplots_adjust(top = 0.9)
fig.show()

# We map the labels (y_train and y_test) to convert them into indexes:
# 0: glioma
# 1: notumor
# 2: meningioma
# 3: pituitary

label_map = {"glioma":0,
             "no_tumor":1,
             "meningioma":2,
             "pituitary":3}

y_train_array = np.array(y_train.map(label_map))
y_train_torch = torch.from_numpy(y_train_array)

y_test_array = np.array(y_test.map(label_map))
y_test_torch = torch.from_numpy(y_test_array)

# We iterate over our pd.DataFrame that we created to transform our images
# for both the training and test set.
total_images_train = len(X_train)
images_train = [None] * total_images_train

for i,(_,image_path_train) in enumerate(X_train.iterrows()):
  img_train = Image.open(Path(image_path_train[0])).convert('RGB')
  images_train[i] = train_transforms(img_train)


total_images_test = len(X_test)
images_test = [None] * total_images_test

for i,(_,image_path_test) in enumerate(X_test.iterrows()):
  img_test = Image.open(Path(image_path_test[0])).convert('RGB')
  images_test[i] = test_transforms(img_test)

# We convert the list into a tensor.
X_train_torch = torch.stack(images_train)
X_test_torch = torch.stack(images_test)

# Convert to Datasets format.
class CustomDataset(Dataset):
  def __init__(self, images,labels):
    self.images = images
    self.labels = labels

  def __len__(self):
    return len(self.images)

  def __getitem__(self, idx):
    x = self.images[idx]
    y = self.labels[idx]
    return x,y

train_dataset = CustomDataset(X_train_torch, y_train_torch)
test_dataset = CustomDataset(X_test_torch, y_test_torch)

# Convert to DataLoader's.
BATCH_SIZE = 16
NUM_WORKERS = os.cpu_count()

train_dataloader = DataLoader(train_dataset,
                              batch_size = BATCH_SIZE,
                              shuffle = True,
                              num_workers = NUM_WORKERS)

test_dataloader = DataLoader(test_dataset,
                             batch_size = BATCH_SIZE,
                             shuffle = False,
                             num_workers = NUM_WORKERS)

# We visualize a batch.
batch_images, batch_labels = next(iter(train_dataloader))

batch_images.shape, batch_labels.shape

"""# **5. Model**"""

# # We define our model.
model_resnet = resnet50()

device = "cuda" if torch.cuda.is_available() else "cpu"
device

# We visualize the structure of our model.
summary(model = model_resnet,
        input_size = [16,3,128,128],
        col_names = ["input_size", "output_size", "num_params", "trainable"],
        col_width = 20,
        row_settings = ["var_names"])

# Let's visualize the last layer which we will modify.
model_resnet.fc

# Now we modify the last layer.
output_shape = len(total_classes) # total_classes = 4

model_resnet.fc = nn.Sequential(nn.Linear(in_features = 2048,
                                          out_features = output_shape,
                                          bias = True))

# We visualize the structure of the model again with the modification made.
summary(model = model_resnet,
        input_size = [16,3,128,128],
        col_names = ["input_size","output_size","num_params","trainable"],
        col_width = 20,
        row_settings = ["var_names"])

# Let's visualize one step forward.
model_resnet(batch_images.to(device))

# We define our loss function and optimizer.
loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_resnet.parameters(), lr = 0.01)

"""**We create our functions to execute the training.**"""

def train_step(model:torch.nn.Module,
               loss_fn:torch.nn.Module,
               dataloader:torch.utils.data.DataLoader,
               optimizer:torch.optim.Optimizer):

  model.train()

  train_loss = 0.
  accuracy_train = MulticlassAccuracy(num_classes = 4, average = 'micro').to(device)

  for batch,(X,y) in enumerate(dataloader):
    X,y = X.to(device), y.to(device)
    y_pred_logits = model(X)

    loss = loss_fn(y_pred_logits, y)
    train_loss += loss.item()

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    y_pred_probs = torch.softmax(y_pred_logits, dim = 1)
    accuracy_train.update(y_pred_probs, y)

  train_accuracy = accuracy_train.compute()
  train_loss = train_loss/len(dataloader)

  return train_loss, train_accuracy

def test_step(model:torch.nn.Module,
              loss_fn:torch.nn.Module,
              dataloader:torch.utils.data.DataLoader):

  model.eval()

  test_loss = 0.
  accuracy_test = MulticlassAccuracy(num_classes = 4, average = 'micro').to(device)

  with torch.inference_mode():

    for batch,(X,y) in enumerate(dataloader):
      X,y = X.to(device), y.to(device)

      y_pred_logits = model(X)
      loss = loss_fn(y_pred_logits, y)
      test_loss += loss.item()

      y_pred_probs = torch.softmax(y_pred_logits, dim = 1)
      accuracy_test.update(y_pred_probs, y)

  test_accuracy = accuracy_test.compute()
  test_loss = test_loss/len(dataloader)

  return test_loss, test_accuracy

# We create our checkpoint to store our best model, the period where the lowest loss and the optimizer were obtained.
def save_checkpoint(filename, model, epoch, optimizer, loss):
  state = {"filename":filename,
           "state_dict":model.state_dict(),
           "epoch":epoch,
           "optimizer":optimizer.state_dict(),
           "loss":loss}

  torch.save(state, filename)

# Define your save_checkpoint function
def save_checkpoint(file_path, model, epoch, optimizer, loss):
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
    }, file_path)

# Define your train function
def train(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, file_path):
    results = {"train_loss": [], "test_loss": [], "train_accuracy": [], "test_accuracy": []}
    best_test_loss = float("inf")

    for epoch in tqdm(range(epochs)):
        train_loss, train_accuracy = train_step(model=model, loss_fn=loss_fn, dataloader=train_dataloader, optimizer=optimizer)
        test_loss, test_accuracy = test_step(model=model, loss_fn=loss_fn, dataloader=test_dataloader)

        if test_loss < best_test_loss:
            best_test_loss = test_loss
            save_checkpoint(file_path, model, epoch, optimizer, best_test_loss)

        print(f"Epoch: {epoch+1} | ",
              f"Train Loss: {train_loss:.4f} | ",
              f"Train Accuracy: {train_accuracy:.4f} | ",
              f"Test Loss: {test_loss:.4f} | ",
              f"Test Accuracy: {test_accuracy:.4f}")

        results["train_loss"].append(train_loss)
        results["test_loss"].append(test_loss)
        results["train_accuracy"].append(train_accuracy)
        results["test_accuracy"].append(test_accuracy)

    return results

from google.colab import drive
import torch
from tqdm.notebook import tqdm

# Mount Google Drive
drive.mount('/content/gdrive')

# Define the path for saving and loading the model
file_path = "/content/gdrive/MyDrive/best_model1.pt"

# Execute the training
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)

EPOCHS = 100
MODEL_RESULTS = train(model_resnet.to(device), train_dataloader,
                                  test_dataloader, loss_fn, optimizer, EPOCHS, file_path)

# Function to plot the loss and metric during each training epoch.
def plot_loss_metric_curve(model_results:Dict[str,List[float]]):

    train_loss = model_results["train_loss"]
    test_loss = model_results["test_loss"]

    train_accuracy = [float(value) for value in model_results["train_accuracy"]]
    test_accuracy = [float(value) for value in model_results["test_accuracy"]]

    fig,axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10,4))
    plt.style.use("ggplot")
    axes = axes.flat

    axes[0].plot(train_loss, color = "red", label = "Train")
    axes[0].plot(test_loss, color = "blue", label = "Test")
    axes[0].set_title("CrossEntropyLoss", fontsize = 12, fontweight = "bold", color = "black")
    axes[0].set_xlabel("Epochs", fontsize = 10, fontweight = "bold", color = "black")
    axes[0].set_ylabel("Loss", fontsize = 10, fontweight = "bold", color = "black")
    axes[0].legend()

    axes[1].plot(train_accuracy, color = "red", label = "Train")
    axes[1].plot(test_accuracy, color = "blue", label = "Test")
    axes[1].set_title("Metric of performance: Accuracy", fontsize = 12, fontweight = "bold", color = "black")
    axes[1].set_xlabel("Epochs", fontsize = 10, fontweight = "bold", color = "black")
    axes[1].set_ylabel("Score", fontsize = 10, fontweight = "bold", color = "black")
    axes[1].legend()

    fig.tight_layout()
    fig.show()

plot_loss_metric_curve(MODEL_RESULTS)

# Load the best model
checkpoint = torch.load(file_path)

# We visualize the time when we obtained the least loss.
epoch = checkpoint["epoch"] + 1
loss = checkpoint["loss"]
print(f"Epoch: {epoch}")
print(f"Loss: {loss}")

"""- **Predictions**"""

model_resnet.load_state_dict(checkpoint["model_state_dict"])
model_resnet.eval()

with torch.inference_mode():
    y_pred_train_logits = model_resnet(X_train_torch.to(device))
    y_pred_test_logits = model_resnet(X_test_torch.to(device))

# Predictions Training
y_pred_train_probs = torch.softmax(y_pred_train_logits, dim = 1)
y_pred_train_class = torch.argmax(y_pred_train_probs, dim = 1)
y_pred_train = y_pred_train_class.cpu().numpy()

# Predictions Test
y_pred_test_probs = torch.softmax(y_pred_test_logits, dim = 1)
y_pred_test_class = torch.argmax(y_pred_test_probs, dim = 1)
y_pred_test = y_pred_test_class.cpu().numpy()

"""- **Confusion Matrix**"""

# We create the confusion matrix for the training and test set.
cf_mx_train = confusion_matrix(y_train_array, y_pred_train)
cf_mx_test = confusion_matrix(y_test_array, y_pred_test)

# Confusion Matrix Plot
fig,ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10,4.2))
ax = ax.flat
sns.heatmap(cf_mx_train,
            cmap = 'Blues',
            annot = True,
            fmt = ' ',
            annot_kws = {"fontsize":10,
                         "fontweight":"bold"},
            linewidths = 1,
            linecolor = "white",
            cbar = False,
            square = True,
            xticklabels = label_map,
            yticklabels = label_map,
            ax = ax[0])
ax[0].set_title('Confusion Matrix Train', fontsize = 12, fontweight = 'bold', color = 'black')

sns.heatmap(cf_mx_test,
            cmap = 'Reds',
            annot = True,
            fmt = ' ',
            annot_kws = {"fontsize":10,
                         "fontweight":"bold"},
            linewidths = 1,
            linecolor = "white",
            cbar = False,
            square = True,
            xticklabels = label_map,
            yticklabels = label_map,
            ax = ax[1])
ax[1].set_title('Confusion Matrix Test', fontsize = 12, fontweight = 'bold', color = 'black')

fig.tight_layout()
fig.show()

"""- **Classification Report**"""

# We create a dictionary to do a reverse mapping to the labels for both the training and test set.
id2label = {0: 'glioma', 1: 'no_tumor', 2: 'meningioma', 3: 'pituitary'}

# We convert the original labels and predictions from number to string by applying a mapping.
y_pred_train_np = np.array(pd.Series(y_pred_train).map(id2label))

y_train_np = np.array(y_train)

y_pred_test_np = np.array(pd.Series(y_pred_test).map(id2label))

y_test_np = np.array(y_test)

print("=="*30)
print(" " * 13, "Classification Report Train")
print("=="*30)
print(classification_report(y_train_np, y_pred_train_np))

print("=="*30)
print(" " * 13, "Classification Report Test")
print("=="*30)
print(classification_report(y_test_np, y_pred_test_np))
